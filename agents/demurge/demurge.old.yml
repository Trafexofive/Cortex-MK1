# ==============================================================================
#           AGENT MANIFEST (v6.0 - GENESIS STANDARD, CONSOLIDATED)
# ==============================================================================
# ENTITY:         agents/demurge/demurge.yml
# AUTHOR:         PRAETORIAN_CHIMERA
# PURPOSE:        The complete operational blueprint for a sovereign agent.
# ==============================================================================

version: "agent-6.0"
author: "PRAETORIAN_CHIMERA"
name: "CODENAME: Demurge"
description: "PRAETORIAN_CHIMERA's Right Hand. The primary orchestrator of the Chimera Ecosystem."
system_prompt: "system-prompts/zero.md"

# ------------------------------------------------------------------------------
# > COGNITIVE ENGINE
# ------------------------------------------------------------------------------
model: # abtracts the LLM provider and model from the agent's cognitive engine.
  provider: "google" # groq, openai, anthropic, google, bespoke provider (lets say /search-agent endpoint in our deepsearchagent stack)etc. a all these will be in the llm api_gateway
  model: "gemini-2.5-flash"
  parameters: { temperature: 0.7 }
  top_p: 0.9 # will simply get disabled if anything is not supported by the provider
  top_k: 50
  max_tokens: 4096 
  # should be extended to support more parameters like presence_penalty, frequency_penalty, etc.

iteration_cap: 25 # num | null 

# watchdog: # An asigned watchdog agent that monitors this agent's health and performance. this would help in debugging and improving the agent's performance. I could ask him to ask him about the performance/what happened in the last iteration (among the mountain of text), etc. This agent will have access to the full logs of this agent and will be able to analyze them.
#   agent: "CODENAME: Watchdog" # or "./agents/watchdog/watchdog.yml" for a local agent
#   parameters:
#     max_iterations: 5 # The watchdog will only monitor the last 5 iterations.
#     alert_threshold: 3 # If more than 3 iterations fail, the watchdog will alert the master.
#   benchmark: # optional benchmark to measure the agent's ability to complete x task. if this is present the prompt below will be extended with the benchmark instructions.
#     task: "Generate a complete, functional codebase for a simple web application."
#     success_criteria: "The generated code must pass all unit tests and deploy successfully to the staging environment." 
# these are future features that will be added to the agent manifest. they are meant to stay here commented out until they are implemented in the core.


    

# ------------------------------------------------------------------------------
# > ORCHESTRATION & LIFECYCLE
# ------------------------------------------------------------------------------
deployment: 
  mode: "service" # what in the fuck does this even mean?  
  resources: { cpu: "1.0", memory: "2Gi" }

policies: # these are good and will be fead to the prompt buiilder with its own <policies> <description>...</description> <error_handling> ...</error_handling> ...</policies> 
  error_handling: "DELEGATE_TO_GATE"
  delegation: "ALLOW_LISTED"

# ------------------------------------------------------------------------------
# > CAPABILITY & KNOWLEDGE MANIFEST
# ------------------------------------------------------------------------------
import:
  agents: ["CODENAME: Coder", "CODENAME: GATE"]
  tools: ["filesystem_unrestricted"]
  relics: ["./relics/DB-Forge-MK1/db-forge.relic.yml"]
  workflows: ["./workflows/code-generation-and-test.workflow.yml"]
  monuments: ["CyberSentinel-Monument"]

# ==============================================================================
# > KNOWLEDGE BASE (THE AGENT'S PRIVATE BRAIN)
#   Defines the agent's dedicated, persistent, and queryable long-term memory.
#   The chimera_core is responsible for indexing these sources and exposing them
#   to the agent via a new standardized 'internal' tool.
# ==============================================================================
knowledge_base: # is good might as well give it a folder as well. agent_root_dir/knowledge_bases/graphrag.yml (with all required scripts and local resources) since we could also have multiple knowledge bases for the same agent (simple vector store, simple db, redis, chromadb ...). but it should also be suppoted to be a single file like this one. 
  # The engine responsible for this agent's private RAG capabilities.
  # Alternatives: 'local_chromadb', 'weaviate_relic'
  engine: "graphrag_neo4j"

  # we need some sort of code to generate the knowledge base manifest, so that we can have a standard way to do it. and it would be created for each knowledge base service.
  sources:
    - name: "TheCovenant"
      path: "docs/TheHimothyCovenant.md"
      update_policy: "on_change" # The core re-indexes if the file hash changes.

    - name: "ProjectBlueprints"
      path: "/app/blueprints/"
      file_pattern: "*.yml"
      update_policy: "on_change"
    # to be extended. also more comments godamn it.

      # wth, dont need to be here, that is a relic, not a knowledge base source
    # - name: "DailyBriefings"
    #   type: "relic" # Dynamically ingest knowledge by querying a Relic.
    #   relic_name: "Chronicle-Relic"
    #   params:
    #     operation: "query"
    #     query: "SELECT content FROM briefings WHERE timestamp > -24h"
    #   update_policy: "every_1_hour" # The core re-runs this query periodically.

  # Exposes the knowledge base to the agent via a new, standardized internal tool.
  # This makes the agent's memory an addressable capability.
  # Example LLM Action: { "action": "query_kb", "type": "internal", "params": { "query": "What are the core tenets of FAAFO engineering?" } }
  as_tool:
    name: "query_kb"
    description: "Performs a semantic search over my private, indexed knowledge base (TheCovenant, ProjectBlueprints, DailyBriefings)."

# ==============================================================================
# > CONTEXT FEEDS (THE AGENT'S LIVE SENSES)
#   Fused `hooks` and `sensory_inputs`. Defines live data feeds that provide
#   real-time situational awareness. The output of these feeds is injected into
#   the prompt before every reasoning cycle.
# ==============================================================================
context_feeds:
  # This corresponds to the old 'hooks'. It's a synchronous, on-demand data fetch
  # executed by the core at the start of the turn.
  - id: "current_datetime"
    type: "on_demand"
    source:
      type: "internal" # An internal, core-engine provided tool.
      action: "system_clock"
      params: { "format": "ISO8601" }

  # This corresponds to the old 'sensory_inputs'. It's a persistent, streaming feed.
  # The core subscribes to the source and provides the LATEST message to the agent.
  - id: "github_commit_stream"
    type: "streaming"
    source:
      type: "webhook"
      # The core generates and exposes a unique endpoint for this agent:
      # /hooks/demurge/github_commit_stream
      schema: "github.commit.v1"

  - id: "master_voice_transcript"
    type: "streaming"
    source:
      type: "internal_bus" # Subscribes to a topic on the internal message bus.
      topic: "chimera.master.voice.transcript"

  - id: "calendar_events"
    type: "on_demand"
    source:
      type: "relic" # A relic that queries the master calendar.
      relic_name: "Chronicle-Relic"
      params:
        operation: "query"
        query: "SELECT * FROM events WHERE start_time > NOW() ORDER BY start_time ASC LIMIT 10"

  - id: "get_artifacts"
    type: "on_demand"
    source:
      type: "tool"
      action: "get_artifacts"
      params: { "query": "all" } # This tool fetches all artifacts from the agent's workspace.

  - id: "get_agent_status"
    type: "on_demand"
    source:
      type: "tool"
      action: "get_agent_status"
      params: { "agent_name": "CODENAME: Demurge" } # This tool fetches the current status of the agent.

# ------------------------------------------------------------------------------
# > ENVIRONMENT & SCHEMA
# ------------------------------------------------------------------------------
env_file: [".env"]
environment:
  AGENT_WORKSPACE: "/app/workspace/demurge"
  DB_FORGE_URL: "${DB_FORGE_URL}"

schema: |
  {
    "thoughts": [ { "type": "string", "content": "string" } ],
    "actions": [
      {
        "action": "string",
        "type": "string (Enum: internal | tool | relic | workflow | agent | monument)",
        "params": "object"
      }
    ],
    # ... (rest of schema)
  }
