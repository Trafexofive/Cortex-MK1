# ğŸ›ï¸ Cortex-Prime MK1

> **"The distance between thought and action, minimized."**

A sovereign AI orchestration platform enabling production-grade agentic systems through declarative manifests, streaming protocol execution, and fractal composability. Born from **agent-lib**, evolved into a complete framework for building, deploying, and orchestrating intelligent agents.

[![Agent-Lib](https://img.shields.io/badge/agent--lib-v1.2-blue)]()
[![Protocol](https://img.shields.io/badge/streaming-XML%2BJSON-purple)]()
[![Manifests](https://img.shields.io/badge/manifests-modern-green)]()
[![License](https://img.shields.io/badge/license-MIT-blue)]()

---

## ğŸ“– Table of Contents

- [What is Cortex-Prime MK1?](#-what-is-cortex-prime-mk1)
- [Quick Start](#-quick-start)
- [Agent-Lib: The Core](#-agent-lib-the-core)
- [Manifest System](#-manifest-system)
- [Architecture](#%EF%B8%8F-architecture)
- [Services](#-services)
- [Development](#-development)
- [Project Structure](#-project-structure)
- [Roadmap](#-roadmap)

---

## ğŸ¯ What is Cortex-Prime MK1?

Cortex-Prime MK1 is a **production-ready agentic AI framework** that treats agents, tools, services, and workflows as composable, self-contained manifests. At its heart is **agent-lib**, a high-performance C++ runtime that executes agents using a streaming XML+JSON fusion protocol.

### Why Cortex-Prime?

**From Daily Driver to Framework** - agent-lib was originally built as a personal daily driver for running AI agents. It evolved into Cortex-Prime MK1, a complete platform that others can use to build their own agentic systems.

**Streaming Protocol First** - Unlike traditional request-response systems, Cortex-Prime uses a **streaming protocol** where agents think, act, and respond in real-time through structured XML+JSON blocks.

**Manifest-Driven Everything** - Agents, tools, relics (services), and even complete stacks are defined in YAML manifests that are modular, composable, and self-contained.

**Production-Grade Execution** - Built in C++ for performance, with Python tooling for flexibility. Real streaming inference, proper context management, and robust error handling.

### Design Principles

**Declarative Reality** - Define what you want, not how to build it. Manifests specify agents, tools, relics (services), and workflows.

**Fractal Composability** - Everything imports everything. Agents import tools. Tools can invoke agents. Relics provide infrastructure. All self-contained and modular.

**CAG Over RAG** - Context-Augmented Generation is first-class. Full context and history are maintained. If you need RAG, build it as a tool or relic.

**Streaming Execution** - Agents don't wait for full responses. They stream thoughts, actions, and responses incrementally using the XML+JSON fusion protocol.

**Self-Contained Modules** - Every agent, tool, and relic is a complete, isolated unit with its own config, scripts, and dependencies.

---

## ğŸ¤– Agent-Lib: The Core

**agent-lib** is the beating heart of Cortex-Prime MK1. Originally a personal daily-driver for AI agents, it's now a production-ready C++ runtime that powers the entire platform.

### Architecture Overview

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    AGENT-LIB v1.2                           â”‚
â”‚              Streaming XML+JSON Fusion Protocol             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                             â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚ CLI Binary   â”‚    â”‚ HTTP Server  â”‚   â”‚  Agent Core  â”‚  â”‚
â”‚  â”‚ ./agent-bin  â”‚â”€â”€â”€â–¶â”‚ FastAPI/C++  â”‚â”€â”€â–¶â”‚   Runtime    â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚                                                  â”‚          â”‚
â”‚         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜          â”‚
â”‚         â”‚                                                   â”‚
â”‚         â–¼                                                   â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚ Manifest Loader (Modern YAML Parser)                 â”‚  â”‚
â”‚  â”‚ â”œâ”€ Agent manifests (cognitive config)                â”‚  â”‚
â”‚  â”‚ â”œâ”€ Tool manifests (capabilities)                     â”‚  â”‚
â”‚  â”‚ â”œâ”€ Relic manifests (services)                        â”‚  â”‚
â”‚  â”‚ â””â”€ Auto-import from std/manifests                    â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚                 â”‚                                           â”‚
â”‚                 â–¼                                           â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚ Streaming Protocol Parser                            â”‚  â”‚
â”‚  â”‚ â”œâ”€ <thought> blocks - Internal reasoning             â”‚  â”‚
â”‚  â”‚ â”œâ”€ <action> blocks - Tool/agent invocations          â”‚  â”‚
â”‚  â”‚ â”œâ”€ <response> blocks - User-facing messages          â”‚  â”‚
â”‚  â”‚ â””â”€ Non-terminating flag support                      â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚                 â”‚                                           â”‚
â”‚                 â–¼                                           â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚ Action Executor                                       â”‚  â”‚
â”‚  â”‚ â”œâ”€ Tool execution (Python/Node/Shell/Docker)         â”‚  â”‚
â”‚  â”‚ â”œâ”€ Sub-agent delegation (streaming passthrough)      â”‚  â”‚
â”‚  â”‚ â”œâ”€ Relic API calls (HTTP/gRPC)                       â”‚  â”‚
â”‚  â”‚ â”œâ”€ Internal actions (system_clock, variables)        â”‚  â”‚
â”‚  â”‚ â””â”€ Result storage & context injection                â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚                 â”‚                                           â”‚
â”‚                 â–¼                                           â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚ Context Manager                                       â”‚  â”‚
â”‚  â”‚ â”œâ”€ Full conversation history (CAG, not RAG)          â”‚  â”‚
â”‚  â”‚ â”œâ”€ Action results                                    â”‚  â”‚
â”‚  â”‚ â”œâ”€ Context feeds (on-demand data injection)          â”‚  â”‚
â”‚  â”‚ â”œâ”€ Variable expansion ($TIMESTAMP, $AGENT_NAME, etc) â”‚  â”‚
â”‚  â”‚ â””â”€ Environment variables                             â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚                                                             â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚ LLM Gateway Integration                               â”‚  â”‚
â”‚  â”‚ â””â”€ Streaming inference (Google Gemini, Groq, etc)    â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚                                                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Key Features

#### âœ… **Streaming Protocol Execution**
Real-time XML+JSON fusion protocol that enables agents to think, act, and respond incrementally:

```xml
<thought>
I need to check the current time before responding.
</thought>

<action>
{
  "name": "system_clock",
  "parameters": {
    "format": "ISO8601",
    "timezone": "UTC"
  }
}
</action>

<response non_terminating="false">
The current time is 2025-01-15 14:23:45 UTC. How can I help you?
</response>
```

#### âœ… **Modern Manifest System**
Self-contained, modular manifests for agents, tools, and relics:

```yaml
kind: Agent
version: "1.0"
name: "sage"
summary: "Research and knowledge advisor"

cognitive_engine:
  primary:
    provider: "google"
    model: "gemini-2.0-flash"
  parameters:
    temperature: 0.3
    max_tokens: 8192
    stream: true

import:
  tools:
    - "knowledge_retriever"
    - "fact_checker"

context_feeds:
  - id: "current_datetime"
    type: "on_demand"
    source:
      type: "internal"
      action: "system_clock"
```

#### âœ… **Tool System**
Tools are self-contained modules with their own manifests and executables:

```yaml
kind: Tool
version: "1.0"
name: "knowledge_retriever"

description: "Search knowledge base for information"

executor:
  runtime: "python"
  script: "./scripts/knowledge_retriever.py"

parameters:
  query:
    type: "string"
    required: true
  depth:
    type: "string"
    enum: ["quick", "deep"]
    default: "quick"
```

#### âœ… **Sub-Agent Delegation**
Agents can invoke other agents, streaming their responses:

```xml
<action>
{
  "name": "delegate_to_agent",
  "parameters": {
    "agent": "research_assistant",
    "prompt": "Find recent papers on quantum computing"
  }
}
</action>
```

#### âœ… **Context Feeds**
Dynamic data injection at runtime:

```yaml
context_feeds:
  - id: "current_datetime"
    type: "on_demand"
    source:
      type: "internal"
      action: "system_clock"
      
  - id: "research_session"
    type: "on_demand"
    source:
      type: "tool"
      tool: "session_retriever"
```

#### âœ… **Internal Actions**
Built-in capabilities available to all agents:

- `system_clock` - Current timestamp with timezone support
- `agent_metadata` - Agent configuration and state
- `context_feed_manager` - Dynamic context injection
- `variable_manager` - Variable expansion and storage

### Build & Run

```bash
cd services/agent-lib

# Build binaries
make                 # Build both CLI and server
make bin            # Build CLI only
make server         # Build server only

# Run
./agent-bin -l config/agents/sage/agent.yml
./agent-server      # Start HTTP server (port 8090)

# Clean
make clean          # Remove binaries
make fclean         # Deep clean (includes build artifacts)
```

### Agent Manifests

Agent-lib includes production-ready agents in `config/agents/`:

- **sage** - Research and knowledge advisor (uses knowledge_retriever, fact_checker)
- **demurge** - Creative problem solver and system builder
- More coming...

### Extending Agent-Lib

Create your own agents by:

1. **Create manifest**: `config/agents/my_agent/agent.yml`
2. **Add system prompt**: `config/agents/my_agent/system-prompts/my_agent.md`
3. **Add tools** (optional): `config/agents/my_agent/tools/my_tool/tool.yml`
4. **Load and run**: `./agent-bin -l config/agents/my_agent/agent.yml`

---

## ğŸ“œ Manifest System

### Manifest Hierarchy

Cortex-Prime uses a **fractal hierarchy** of manifest types, each self-contained and modular:

#### ğŸ”§ **Tools**
Atomic, stateless capabilities. Execute single tasks.

```yaml
kind: Tool
version: "1.0"
name: "fact_checker"

description: "Verify factual claims and check logical consistency"

executor:
  runtime: "python"
  script: "./scripts/fact_checker.py"

parameters:
  claim:
    type: "string"
    required: true
    description: "The claim to verify"
  
  check_sources:
    type: "boolean"
    default: true
    description: "Whether to verify against known sources"

output_schema:
  type: "object"
  properties:
    verified:
      type: "boolean"
    confidence:
      type: "number"
    sources:
      type: "array"
```

#### ğŸº **Relics**
Self-contained services with lifecycle management.

```yaml
kind: Relic
version: "1.0"
name: "vector_store"

description: "Persistent vector database for embeddings"

service:
  type: "docker-compose"
  compose_file: "./docker-compose.yml"
  health_check:
    endpoint: "http://localhost:8004/health"
    interval: 30
  auto_start: true

endpoints:
  embed: "http://vector-store:8004/embed"
  search: "http://vector-store:8004/search"

environment:
  variables:
    VECTOR_DIM: "768"
    INDEX_TYPE: "HNSW"
```

#### ğŸ¤– **Agents**
Intelligent entities that use tools and relics.

```yaml
kind: Agent
version: "1.0"
name: "research_agent"

persona:
  agent: "./system-prompts/agent.md"

cognitive_engine:
  primary:
    provider: "google"
    model: "gemini-1.5-flash"
  
  fallback:
    provider: "groq"
    model: "llama-3.1-70b-versatile"
  
  parameters:
    temperature: 0.7
    max_tokens: 4096
    stream: true

import:
  tools:
    - "web_search"
    - "knowledge_retriever"
  
  relics:
    - "vector_store"
  
  agents:
    - "fact_checker_agent"  # Sub-agent delegation

context_feeds:
  - id: "current_time"
    type: "on_demand"
    source:
      type: "internal"
      action: "system_clock"

environment:
  variables:
    WORKSPACE: "$HOME/research/$SESSION_ID"
```

#### ğŸ“œ **Workflows**
Multi-step orchestration (planned).

```yaml
kind: Workflow
version: "1.0"
name: "research_pipeline"

steps:
  - name: "gather"
    agent: "web_researcher"
    
  - name: "analyze"
    agent: "data_analyst"
    depends_on: ["gather"]
    
  - name: "synthesize"
    agent: "report_writer"
    depends_on: ["analyze"]
```

#### ğŸ›ï¸ **Monuments**
Complete systems composed of multiple entities (planned).

```yaml
kind: Monument
version: "1.0"
name: "knowledge_platform"

relics:
  - vector_store
  - graph_database
  - search_engine

agents:
  - researcher
  - synthesizer
  - curator

workflows:
  - ingestion_pipeline
  - query_pipeline
```

### Manifest Location

Manifests are organized in two locations:

1. **Local** - `config/agents/`, `config/tools/`, etc. (agent-specific)
2. **Standard Library** - `std/manifests/` (shared across system)

```
services/agent-lib/
â”œâ”€â”€ config/
â”‚   â”œâ”€â”€ agents/
â”‚   â”‚   â”œâ”€â”€ sage/
â”‚   â”‚   â”‚   â”œâ”€â”€ agent.yml
â”‚   â”‚   â”‚   â”œâ”€â”€ system-prompts/
â”‚   â”‚   â”‚   â”‚   â””â”€â”€ sage.md
â”‚   â”‚   â”‚   â””â”€â”€ tools/
â”‚   â”‚   â”‚       â”œâ”€â”€ knowledge_retriever/
â”‚   â”‚   â”‚       â”‚   â”œâ”€â”€ tool.yml
â”‚   â”‚   â”‚       â”‚   â””â”€â”€ scripts/
â”‚   â”‚   â”‚       â”‚       â””â”€â”€ knowledge_retriever.py
â”‚   â”‚   â”‚       â””â”€â”€ fact_checker/
â”‚   â”‚   â”‚           â”œâ”€â”€ tool.yml
â”‚   â”‚   â”‚           â””â”€â”€ scripts/
â”‚   â”‚   â”‚               â””â”€â”€ fact_checker.py
â”‚   â”‚   â””â”€â”€ demurge/
â”‚   â”‚       â””â”€â”€ agent.yml
â”‚   â”‚
â”‚   â””â”€â”€ relics/
â”‚       â””â”€â”€ (planned)

std/manifests/
â”œâ”€â”€ agents/
â”œâ”€â”€ tools/
â”œâ”€â”€ relics/
â”œâ”€â”€ workflows/
â””â”€â”€ monuments/
```

### Fractal Composability

The true power is **cross-manifest imports**:

```yaml
# Agent imports tools and other agents
kind: Agent
name: "senior_developer"
import:
  tools: ["git", "docker", "pytest"]
  agents: ["code_reviewer", "documentation_writer"]
  relics: ["ci_server"]
```

```yaml
# Tool can invoke agents for intelligent processing
kind: Tool
name: "smart_refactor"
import:
  agents: ["syntax_analyzer"]
```

This creates a **fractal hierarchy** where complexity emerges from simple primitives.

---

## ğŸ—ï¸ Architecture

### System Overview

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                   Cortex-Prime MK1 Stack                     â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                              â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”       â”‚
â”‚  â”‚   Agent-Lib v1.2   â”‚         â”‚   LLM Gateway    â”‚       â”‚
â”‚  â”‚   (C++ Runtime)    â”‚â—„â”€â”€â”€â”€â”€â”€â”€â”€â”¤   (Multi-LLM)    â”‚       â”‚
â”‚  â”‚   Port: 8090       â”‚ Stream  â”‚   Port: 8081     â”‚       â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜       â”‚
â”‚             â”‚                                                â”‚
â”‚             â”‚ Manifests (YAML)                              â”‚
â”‚             â–¼                                                â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”              â”‚
â”‚  â”‚  Manifest Registry                       â”‚              â”‚
â”‚  â”‚  â”œâ”€ Agents (cognitive profiles)          â”‚              â”‚
â”‚  â”‚  â”œâ”€ Tools (atomic capabilities)          â”‚              â”‚
â”‚  â”‚  â”œâ”€ Relics (service wrappers)           â”‚              â”‚
â”‚  â”‚  â”œâ”€ Workflows (orchestration)           â”‚              â”‚
â”‚  â”‚  â””â”€ Monuments (complete stacks)         â”‚              â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜              â”‚
â”‚                                                              â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”              â”‚
â”‚  â”‚  Supporting Services (Optional)          â”‚              â”‚
â”‚  â”‚  â”œâ”€ Manifest Ingestion (FastAPI)         â”‚              â”‚
â”‚  â”‚  â”œâ”€ Runtime Executor (Sandboxed)         â”‚              â”‚
â”‚  â”‚  â”œâ”€ B-Line Dashboard (Next.js)           â”‚              â”‚
â”‚  â”‚  â”œâ”€ Neo4j (Graph DB)                     â”‚              â”‚
â”‚  â”‚  â”œâ”€ Redis (Cache/State)                  â”‚              â”‚
â”‚  â”‚  â””â”€ PostgreSQL (Relational)              â”‚              â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜              â”‚
â”‚                                                              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Core Components

#### **Agent-Lib** (Primary Runtime)
- **Language**: C++ for performance
- **Purpose**: Execute agents using streaming protocol
- **Key Features**: 
  - Real-time streaming inference
  - Tool execution (Python/Node/Shell/Docker)
  - Sub-agent delegation
  - Context feed management
  - Internal action system

#### **LLM Gateway** (AI Provider Abstraction)
- **Language**: Python (FastAPI)
- **Purpose**: Multi-provider LLM access with streaming
- **Providers**: Google Gemini, Groq, Ollama (local)
- **Free Tier**: Use Gemini for zero-cost inference

#### **Manifest Ingestion** (Optional, for hot-reload)
- **Language**: Python (FastAPI)
- **Purpose**: Parse, validate, and registry manifests
- **Features**: Filesystem watching, validation, dependency resolution

#### **Runtime Executor** (Optional, for distributed execution)
- **Language**: Python (FastAPI)
- **Purpose**: Sandboxed tool execution in containers
- **Use Case**: When you need isolation from agent process

### Data Flow

1. **User Input** â†’ Agent-Lib CLI/Server
2. **Context Building** â†’ Full history + context feeds + variables
3. **LLM Request** â†’ Streaming inference via LLM Gateway
4. **Protocol Parsing** â†’ Real-time XML+JSON block extraction
5. **Action Execution** â†’ Tools, sub-agents, relics, internal actions
6. **Result Injection** â†’ Results added to context
7. **Iteration** â†’ Repeat until response or iteration cap
8. **User Output** â†’ Final response delivered

### Execution Flow

```
User Input
    â”‚
    â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Agent-Lib Core     â”‚
â”‚  - Load manifest    â”‚
â”‚  - Build context    â”‚
â”‚  - Init conversationâ”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
           â”‚
           â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  LLM Gateway        â”‚
â”‚  - Stream request   â”‚
â”‚  - Real-time tokens â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
           â”‚ Stream
           â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Protocol Parser    â”‚
â”‚  - Extract <thought>â”‚
â”‚  - Extract <action> â”‚
â”‚  - Extract <response>â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
           â”‚
           â–¼
     <action> found?
           â”‚
      â”Œâ”€â”€â”€â”€â”´â”€â”€â”€â”€â”
      â”‚         â”‚
     Yes       No
      â”‚         â”‚
      â–¼         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  Output
â”‚ Execute  â”‚  Response
â”‚ Action   â”‚     â”‚
â”‚ (Tool/   â”‚     â”‚
â”‚  Agent/  â”‚     â”‚
â”‚  Relic)  â”‚     â”‚
â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜     â”‚
     â”‚           â”‚
     â–¼           â”‚
  Inject         â”‚
  Result         â”‚
     â”‚           â”‚
     â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜
           â”‚
    Iteration++
           â”‚
    Continue? (iteration < cap)
           â”‚
      â”Œâ”€â”€â”€â”€â”´â”€â”€â”€â”€â”
      â”‚         â”‚
     Yes       No
      â”‚         â”‚
      â””â”€â”€â”€â”€â”    â””â”€â†’ End
           â”‚
           â–¼
      Repeat
```

---

## ğŸš€ Quick Start

### Prerequisites

- **Linux** (tested on Ubuntu/Debian)
- **C++ Compiler** (g++ 9.0+)
- **Python 3.8+**
- **Make** (GNU Make 4.0+)
- **Docker** (optional, for relics/services)

### 60-Second Setup (Agent-Lib Binary)

```bash
# Clone the repository
git clone https://github.com/Trafexofive/Cortex-Prime-MK1.git
cd Cortex-Prime-MK1/services/agent-lib

# Set your API key (required)
export LLM_GATEWAY_API_KEY="your-google-api-key"

# Build the agent binary
make

# Run an agent (interactive CLI)
./agent-bin -l config/agents/sage/agent.yml
```

**That's it.** You now have a fully functional AI agent running locally.

### Your First Interaction

```bash
./agent-bin -l config/agents/sage/agent.yml

> hello
[Streaming...]
Hello! I am Sage, ready to assist you with your inquiries. How can I help you today?

> what can you do?
[Streaming...]
I am Sage, a knowledgeable advisor designed to assist you with complex questions...
[Shows capabilities, tools, approach]

> /tools
Available tools:
  - fact_checker: Verify factual claims
  - knowledge_retriever: Search knowledge base

> /quit
Goodbye!
```

### CLI Flags

```bash
./agent-bin -h              # Show help
./agent-bin -l <path>       # Load manifest
./agent-bin -v              # Verbose logging
./agent-bin --stream        # Force streaming mode (default)
```

### Available Commands

While chatting with an agent:

```
/load <path>    - Load different agent manifest
/reload         - Reload current manifest
/stream on|off  - Toggle streaming mode
/tools          - List available tools
/info           - Show agent configuration
/clear          - Clear conversation history
/help           - Show command help
/quit or /exit  - Exit CLI
```

---

## ğŸ”§ Services

Cortex-Prime is designed as a modular ecosystem. **Agent-lib is standalone**, but you can add supporting services for advanced features.

### Core Service (Required)

| Service | Purpose | Language | Port | Status |
|---------|---------|----------|------|--------|
| **Agent-Lib** | Agent execution runtime | C++ | 8090 | âœ… Production |
| **LLM Gateway** | Multi-provider LLM access | Python | 8081 | âœ… Production |

### Optional Services

| Service | Purpose | Language | Port | Status |
|---------|---------|----------|------|--------|
| **Manifest Ingestion** | Hot-reload & validation | Python | 8082 | âœ… Available |
| **Runtime Executor** | Distributed tool execution | Python | 8083 | âœ… Available |
| **B-Line Dashboard** | Web UI for manifests | Next.js | 3000 | âœ… Available |
| **Chat Test** | Protocol testing UI | Python | 8888 | âœ… Available |

### Infrastructure (Optional)

| Service | Purpose | Port | Status |
|---------|---------|------|--------|
| **Neo4j** | Knowledge graph storage | 7474/7687 | âš™ï¸ Ready |
| **Redis** | Caching & state | 6379 | âš™ï¸ Ready |
| **PostgreSQL** | Relational storage | 5432 | âš™ï¸ Ready |

### Running Services

```bash
# Minimal (agent-lib only)
cd services/agent-lib && make && ./agent-bin -l config/agents/sage/agent.yml

# With LLM Gateway (for streaming inference)
cd services/llm_gateway && docker-compose up -d

# Full stack (all services)
cd /path/to/Cortex-Prime-MK1
docker-compose up -d
```

---

The true power of Cortex-Prime is **cross-manifest imports**:

```yaml
# Agent imports tools and other agents
kind: Agent
name: "senior_developer"
import:
  tools: ["git", "docker", "pytest"]
  agents: ["code_reviewer", "documentation_writer"]
  relics: ["ci_server", "artifact_storage"]
```

```yaml
# Tool imports an agent for intelligent processing
kind: Tool
name: "smart_refactor"
executor: "docker"
import:
  agents: ["syntax_analyzer"]  # Tool uses an agent!
```

```yaml
# Relic imports workflows for automation
kind: Relic
name: "auto_scaling_cluster"
import:
  workflows: ["health_check_loop", "scale_decision"]
```

This creates a **fractal hierarchy** where complexity emerges from simple, composable primitives.

### Context Variables (22+ Built-in)

Manifests support dynamic variables that resolve at runtime:

**Temporal:**
- `$TIMESTAMP` - Current UTC timestamp (ISO 8601)
- `$DATE`, `$TIME`, `$YEAR`, `$MONTH`, `$DAY`

**Identity:**
- `$AGENT_ID`, `$AGENT_NAME` - Agent identity
- `$TOOL_ID`, `$TOOL_NAME` - Tool identity
- `$SESSION_ID`, `$USER_ID` - Session context

**Environment:**
- `$HOME`, `$USER`, `$PWD`, `$HOSTNAME`

**Execution State:**
- `$ITERATION_COUNT`, `$CONFIDENCE`, `$ERROR_COUNT`

**Example:**
```yaml
environment:
  variables:
    LOG_DIR: "/logs/$AGENT_NAME/$SESSION_ID"
    WORKSPACE: "$HOME/cortex/$DATE"
    # Resolves to: /logs/senior_developer/abc123/
    #              /home/cortex/2025-01-15/
```

### API Endpoints

**Manifest Ingestion Service** - `http://localhost:8082`

| Endpoint | Method | Description |
|----------|--------|-------------|
| `/health` | GET | Service health check |
| `/registry/status` | GET | Registry statistics (counts, manifest types) |
| `/registry/manifest/{kind}/{name}` | GET | Retrieve specific manifest |
| `/registry/agents` | GET | List all agent manifests |
| `/registry/tools` | GET | List all tool manifests |
| `/registry/relics` | GET | List all relic manifests |
| `/registry/sync` | POST | Force filesystem sync |
| `/manifests/upload` | POST | Upload manifest file |
| `/manifests/validate` | POST | Validate manifest without storing |
| `/docs` | GET | Interactive OpenAPI documentation |

---

## ğŸ› ï¸ Development

### Agent-Lib Development

```bash
cd services/agent-lib

# Build
make                # Build both CLI and server
make bin            # CLI only
make server         # Server only
make clean          # Remove binaries
make fclean         # Deep clean

# Run
./agent-bin -l config/agents/sage/agent.yml
./agent-server      # HTTP server on port 8090

# Test
make test           # Run all tests
./test_all_manifests.sh
```

### Docker Stack Development

```bash
# Quick commands
make up STACK=core      # Start core services
make up                 # Start full stack
make down               # Stop services
make restart            # Restart all
make rebuild            # No-cache rebuild

# Monitoring
make status             # Service status
make health             # Health checks
make logs               # All logs
make logs-manifest      # Specific service
make logs-runtime
make logs-agent-lib

# Testing
make test               # All tests
make test-manifest      # Specific service
make test-runtime
make test-integration

# Debugging
make ssh service=agent_lib          # Shell into container
make exec svc=agent_lib cmd="ls"    # Run command

# Cleaning
make clean              # Remove containers
make fclean             # Remove volumes too
make prune              # Nuclear option
```

### Creating Your Own Agent

1. **Create directory structure**:

```bash
mkdir -p config/agents/my_agent/system-prompts
mkdir -p config/agents/my_agent/tools
```

2. **Create agent manifest** (`config/agents/my_agent/agent.yml`):

```yaml
kind: Agent
version: "1.0"
name: "my_agent"
summary: "Your agent description"
author: "YOUR_NAME"
state: "unstable"

persona:
  agent: "./system-prompts/my_agent.md"

cognitive_engine:
  primary:
    provider: "google"
    model: "gemini-2.0-flash"
  parameters:
    temperature: 0.7
    max_tokens: 4096
    stream: true

import:
  tools: []

iteration_cap: 10
```

3. **Create system prompt** (`config/agents/my_agent/system-prompts/my_agent.md`):

```markdown
# My Agent

You are My Agent, a helpful assistant.

## Core Capabilities
- Capability 1
- Capability 2

## Response Format
Use the streaming protocol:
- <thought> for internal reasoning
- <action> for tool calls
- <response> for user messages
```

4. **Load and test**:

```bash
./agent-bin -l config/agents/my_agent/agent.yml
```

### Creating Custom Tools

1. **Create tool directory**:

```bash
mkdir -p config/agents/my_agent/tools/my_tool/scripts
```

2. **Create tool manifest** (`tool.yml`):

```yaml
kind: Tool
version: "1.0"
name: "my_tool"

description: "Tool description"

executor:
  runtime: "python"
  script: "./scripts/my_tool.py"

parameters:
  input_param:
    type: "string"
    required: true
    description: "Input parameter"

output_schema:
  type: "object"
  properties:
    result:
      type: "string"
```

3. **Create tool script** (`scripts/my_tool.py`):

```python
#!/usr/bin/env python3
import json
import sys

def main():
    # Read parameters from stdin or argv[1]
    if len(sys.argv) > 1:
        params = json.loads(sys.argv[1])
    else:
        params = json.loads(sys.stdin.read())
    
    # Your tool logic here
    result = {
        "success": True,
        "result": "Tool output"
    }
    
    print(json.dumps(result))

if __name__ == "__main__":
    main()
```

4. **Make executable and test**:

```bash
chmod +x config/agents/my_agent/tools/my_tool/scripts/my_tool.py

# Add to agent import
import:
  tools:
    - "my_tool"
```

---

## ğŸ“‚ Project Structure

```
Cortex-Prime-MK1/
â”œâ”€â”€ services/
â”‚   â”œâ”€â”€ agent-lib/                      # â­ Core Runtime (C++)
â”‚   â”‚   â”œâ”€â”€ agent-bin                   # CLI executable
â”‚   â”‚   â”œâ”€â”€ agent-server                # HTTP server
â”‚   â”‚   â”œâ”€â”€ cli.main.cpp                # CLI implementation
â”‚   â”‚   â”œâ”€â”€ src/                        # Core source
â”‚   â”‚   â”‚   â”œâ”€â”€ agent/                  # Agent runtime
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ Agent.cpp           # Main agent class
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ ManifestLoader.cpp  # YAML manifest parsing
â”‚   â”‚   â”‚   â”‚   â””â”€â”€ ContextManager.cpp  # Context & variables
â”‚   â”‚   â”‚   â”œâ”€â”€ protocol/               # Streaming protocol
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ StreamingProtocolParser.cpp
â”‚   â”‚   â”‚   â”‚   â””â”€â”€ ActionExecutor.cpp  # Tool/agent execution
â”‚   â”‚   â”‚   â”œâ”€â”€ tools/                  # Tool registry
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ ToolRegistry.cpp
â”‚   â”‚   â”‚   â”‚   â””â”€â”€ InternalTools.cpp   # Built-in tools
â”‚   â”‚   â”‚   â””â”€â”€ llm/                    # LLM integration
â”‚   â”‚   â”‚       â””â”€â”€ LLMGatewayClient.cpp
â”‚   â”‚   â”œâ”€â”€ inc/                        # Headers
â”‚   â”‚   â”œâ”€â”€ config/                     # Agent manifests
â”‚   â”‚   â”‚   â”œâ”€â”€ agents/
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ sage/               # Research advisor
â”‚   â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ agent.yml
â”‚   â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ system-prompts/
â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â””â”€â”€ sage.md
â”‚   â”‚   â”‚   â”‚   â”‚   â””â”€â”€ tools/
â”‚   â”‚   â”‚   â”‚   â”‚       â”œâ”€â”€ knowledge_retriever/
â”‚   â”‚   â”‚   â”‚   â”‚       â”‚   â”œâ”€â”€ tool.yml
â”‚   â”‚   â”‚   â”‚   â”‚       â”‚   â””â”€â”€ scripts/
â”‚   â”‚   â”‚   â”‚   â”‚       â”‚       â””â”€â”€ knowledge_retriever.py
â”‚   â”‚   â”‚   â”‚   â”‚       â””â”€â”€ fact_checker/
â”‚   â”‚   â”‚   â”‚   â”‚           â”œâ”€â”€ tool.yml
â”‚   â”‚   â”‚   â”‚   â”‚           â””â”€â”€ scripts/
â”‚   â”‚   â”‚   â”‚   â”‚               â””â”€â”€ fact_checker.py
â”‚   â”‚   â”‚   â”‚   â””â”€â”€ demurge/            # Creative builder
â”‚   â”‚   â”‚   â”‚       â””â”€â”€ agent.yml
â”‚   â”‚   â”‚   â””â”€â”€ _archive/               # Old manifests
â”‚   â”‚   â”œâ”€â”€ Makefile                    # Build system
â”‚   â”‚   â””â”€â”€ README.md
â”‚   â”‚
â”‚   â”œâ”€â”€ llm_gateway/                    # LLM Provider Abstraction
â”‚   â”‚   â”œâ”€â”€ main.py                     # FastAPI server
â”‚   â”‚   â”œâ”€â”€ providers/                  # Multi-provider support
â”‚   â”‚   â”‚   â”œâ”€â”€ google.py               # Gemini
â”‚   â”‚   â”‚   â”œâ”€â”€ groq.py                 # Groq
â”‚   â”‚   â”‚   â””â”€â”€ ollama.py               # Local models
â”‚   â”‚   â””â”€â”€ Dockerfile
â”‚   â”‚
â”‚   â”œâ”€â”€ manifest_ingestion/             # Manifest Parser (Optional)
â”‚   â”‚   â”œâ”€â”€ main.py
â”‚   â”‚   â”œâ”€â”€ parsers/
â”‚   â”‚   â”œâ”€â”€ models/
â”‚   â”‚   â”œâ”€â”€ registry/
â”‚   â”‚   â””â”€â”€ tests/
â”‚   â”‚
â”‚   â”œâ”€â”€ runtime_executor/               # Sandboxed Execution (Optional)
â”‚   â”‚   â”œâ”€â”€ main.py
â”‚   â”‚   â”œâ”€â”€ executors/
â”‚   â”‚   â””â”€â”€ tests/
â”‚   â”‚
â”‚   â”œâ”€â”€ b-line/                         # Web Dashboard (Optional)
â”‚   â”‚   â”œâ”€â”€ app/
â”‚   â”‚   â”œâ”€â”€ components/
â”‚   â”‚   â””â”€â”€ lib/
â”‚   â”‚
â”‚   â””â”€â”€ chat_test/                      # Protocol Tester (Optional)
â”‚       â””â”€â”€ chat_test_service.py
â”‚
â”œâ”€â”€ std/                                # Standard Library
â”‚   â””â”€â”€ manifests/
â”‚       â”œâ”€â”€ agents/                     # Shared agent manifests
â”‚       â”œâ”€â”€ tools/                      # Shared tool manifests
â”‚       â”œâ”€â”€ relics/                     # Service manifests
â”‚       â”œâ”€â”€ workflows/                  # Workflow definitions
â”‚       â””â”€â”€ monuments/                  # Complete stacks
â”‚
â”œâ”€â”€ examples/                           # Example use cases
â”‚   â”œâ”€â”€ simple_agent/
â”‚   â”œâ”€â”€ tool_chaining/
â”‚   â””â”€â”€ custom_workflow/
â”‚
â”œâ”€â”€ docs/                               # Documentation
â”‚   â”œâ”€â”€ STREAMING_PROTOCOL.md
â”‚   â”œâ”€â”€ MANIFEST_REFERENCE.md
â”‚   â”œâ”€â”€ ROADMAP.md
â”‚   â””â”€â”€ ARCHITECTURE.md
â”‚
â”œâ”€â”€ docker-compose.yml                  # Full stack orchestration
â”œâ”€â”€ Makefile                            # Root-level commands
â””â”€â”€ README.md                           # This file
```

### Key Directories

**`services/agent-lib/`** - The core runtime. Completely standalone, no dependencies on other services.

**`services/llm_gateway/`** - Multi-provider LLM access. Used by agent-lib for streaming inference.

**`std/manifests/`** - Standard library of reusable manifests. Agents can import from here.

**`config/agents/`** - Agent-specific manifests. Self-contained with tools, prompts, and configs.

---

## ğŸ“š Documentation

### Core Documentation

- **[services/agent-lib/README.md](services/agent-lib/README.md)** - Agent-lib complete guide
- **[docs/STREAMING_PROTOCOL.md](docs/STREAMING_PROTOCOL.md)** - XML+JSON fusion protocol specification
- **[docs/ROADMAP.md](docs/ROADMAP.md)** - Development roadmap and milestones
- **[TOOL_CREATION_GUIDE.md](TOOL_CREATION_GUIDE.md)** - How to create custom tools

### Service Documentation

- **[services/llm_gateway/README.md](services/llm_gateway/README.md)** - LLM provider integration
- **[services/manifest_ingestion/README.md](services/manifest_ingestion/README.md)** - Manifest validation
- **[services/runtime_executor/README.md](services/runtime_executor/README.md)** - Sandboxed execution
- **[services/b-line/README.md](services/b-line/README.md)** - Web dashboard guide

### Examples

- **[examples/simple_agent/](examples/)** - Basic agent setup
- **[config/agents/sage/](services/agent-lib/config/agents/sage/)** - Production agent example
- **[config/agents/demurge/](services/agent-lib/config/agents/demurge/)** - Creative builder example

---

## ğŸ—ºï¸ Roadmap

### Current Status: Foundation Phase

**Agent-lib v1.2** is production-ready for daily use. The framework is evolving to support advanced features.

### âœ… Completed

**Agent-Lib Core:**
- [x] Streaming XML+JSON protocol parser
- [x] Modern manifest loader (YAML)
- [x] Tool execution system (Python/Node/Shell/Docker)
- [x] Internal action system (system_clock, agent_metadata, etc.)
- [x] Context feed management
- [x] Variable expansion ($TIMESTAMP, $AGENT_NAME, etc.)
- [x] Full conversation history (CAG approach)
- [x] CLI binary with interactive commands
- [x] HTTP server (FastAPI integration)
- [x] LLM Gateway integration (streaming inference)
- [x] Production agents (Sage, Demurge)

**Supporting Services:**
- [x] LLM Gateway (multi-provider streaming)
- [x] Manifest Ingestion (validation & hot-reload)
- [x] Runtime Executor (sandboxed execution)
- [x] B-Line Dashboard (web UI)
- [x] Chat Test (protocol testing)

### ğŸš§ In Progress

**Critical Features:**
- [ ] Sub-agent delegation (streaming passthrough)
- [ ] Non-terminating responses (continue iteration after reply)
- [ ] Relic lifecycle management (health checks, auto-start, monitoring)
- [ ] Context feed expansion (auto-import std library)
- [ ] Action result variable interpolation ($result_key syntax)

**Nice to Have:**
- [ ] Amulet support (reusable config bundles)
- [ ] Workflow engine (multi-step orchestration)
- [ ] Monument deployment (complete stack management)

### ğŸ“‹ Planned

**Phase 1: Enhanced Capabilities**
- Agent memory persistence (Neo4j/PostgreSQL)
- Advanced error handling with retries
- Confidence scoring & self-assessment
- Expanded tool library (20+ production tools)

**Phase 2: Distributed Systems**
- Multi-agent coordination
- Message bus integration (NATS/RabbitMQ)
- Distributed workflow execution
- Agent-to-agent streaming delegation

**Phase 3: Observability**
- Structured logging with context
- Prometheus metrics & Grafana dashboards
- Performance profiling
- Resource usage tracking

**Phase 4: Self-Modification**
- Agent introspection & reflection
- Automated manifest generation
- Dynamic tool creation
- Meta-learning capabilities

---

## ğŸ¯ Use Cases

### What You Can Build

**Personal AI Assistant** - Daily driver for tasks, research, code generation, and creative work. Load different agents for different contexts.

**Research Platform** - Agents with knowledge retrieval, fact-checking, and synthesis capabilities. Build a personal knowledge graph.

**Code Generation System** - Specialized agents for different languages and frameworks. Sub-agents for linting, testing, documentation.

**Creative Writing Assistant** - Story development, character building, world-building with persistent context across sessions.

**Task Automation** - Workflows that chain multiple agents and tools. From simple scripts to complex multi-step processes.

**Custom Relics** - Build containerized services that agents can interact with. Vector stores, databases, APIs, etc.

---

## ğŸ¤ Contributing

Cortex-Prime MK1 is a personal research project exploring autonomous AI architectures. While external contributions aren't currently accepted, you're welcome to:

- **Fork** the repository for your own experiments
- **Open issues** for bugs or feature suggestions
- **Star** the repo if you find it useful
- **Share** your own agent manifests and tools

---

## ğŸ“Š Current Status

**Phase:** Foundation (Production-Ready Core)  
**Agent-Lib Version:** 1.2  
**Active Agents:** 2 (Sage, Demurge)  
**Streaming Protocol:** XML+JSON Fusion  
**Primary Language:** C++ (runtime), Python (services)  
**Daily Driver:** Yes âœ…  
**Production Ready:** Agent-lib core âœ…  

---

## ğŸ“„ License

MIT License - See LICENSE file for details.

---

## ğŸ›ï¸ Philosophy

**"The Great Work Never Ends"**

Cortex-Prime embodies a philosophy of continuous iteration, bold experimentation, and emergent intelligence. We build systems that are:

- **Sovereign** - Run locally, own your data
- **Modular** - Compose complex from simple
- **Transparent** - Open protocols, inspectable behavior
- **Adaptive** - Context-aware, self-improving
- **Unstoppable** - Resilient, fault-tolerant

---

**Built by [PRAETORIAN_CHIMERA](https://github.com/Trafexofive)**  
**Inspired by the daily need for better AI tooling**

---